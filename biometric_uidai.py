# -*- coding: utf-8 -*-
"""Biometric - UIDAI

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Pt79oQ-WtUw6pddnXz3Evkm956IuAAGy

# Libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import json

"""# Important

## Important Lists and Dictionaries
"""

# List of all UTs

UT = ['Andaman & Nicobar Island',
      'Chandigarh',
      'Dadra And Nagar Haveli And Daman And Diu',
      'Delhi',
      'Jammu & Kashmir',
      'Ladakh',
      'Lakshadweep',
      'Puducherry']

# Regions

regions = {
    "Northern Region": [
        "Jammu & Kashmir", "Ladakh", "Himachal Pradesh",
        "Punjab", "Haryana", "Delhi", "Chandigarh",
        "Uttarakhand", "Uttar Pradesh"
    ],

    "Western Region": [
        "Rajasthan", "Gujarat", "Maharashtra", "Goa",
        "Dadra And Nagar Haveli And Daman And Diu",
        "Daman & Diu"
    ],

    "Central Region": [
        "Madhya Pradesh", "Chhattisgarh"
    ],

    "Eastern Region": [
        "West Bengal", "Bihar", "Jharkhand", "Odisha"
    ],

    "North-Eastern Region": [
        "Assam", "Arunanchal Pradesh", "Manipur",
        "Meghalaya", "Mizoram", "Nagaland",
        "Tripura", "Sikkim"
    ],

    "Southern Region": [
        "Andhra Pradesh", "Telangana",
        "Tamil Nadu", "Karnataka",
        "Kerala", "Puducherry"
    ],

    "Island Territories": [
        "Andaman & Nicobar Island",
        "Lakshadweep"
    ]
}

# Metropolitan Cities

metro_city = ['Mumbai',
              'Delhi',
              'Kolkata',
              'Chennai',
              'Bengaluru',
              'Hyderabad',
              'Ahmedabad',
              'Pune']

# Making a State wise mapping with all the variations to their official names

state_mapping = {
    # West Bengal
    'westbengal': 'West Bengal',
    'west bengal': 'West Bengal',
    'west bangal': 'West Bengal',

    # Tamil Nadu
    'tamilnadu': 'Tamil Nadu',
    'tamil nadu': 'Tamil Nadu',

    # Odisha / Orissa
    'orissa': 'Odisha',
    'odisha': 'Odisha',

    # Uttarakhand
    'uttaranchal': 'Uttarakhand',
    'uttarakhand': 'Uttarakhand',

    # Chhattisgarh
    'chhatisgarh': 'Chhattisgarh',
    'chhattisgarh': 'Chhattisgarh',

    # Jammu & Kashmir / Ladakh
    'jammu and kashmir': 'Jammu & Kashmir',
    'jammu kashmir': 'Jammu & Kashmir',

    # Andaman & Nicobar
    'andaman and nicobar islands': 'Andaman & Nicobar Island',

    # Dadra & Nagar Haveli and Daman & Diu
    'dadra and nagar haveli and daman and diu':
        'Dadra and Nagar Haveli and Daman and Diu',
    'dadra and nagar haveli': 'Dadra and Nagar Haveli and Daman and Diu',
    'daman and diu': 'Daman & Diu',

    # Pondicherry
    'pondicherry': 'Puducherry',

    'arunachal pradesh': 'Arunanchal Pradesh'


}

district_mapping = {
    # Hooghly variants
    'hooghly': 'Hooghly',
    'haora': 'Hooghly',
    'hooghiy': 'Hooghly',
    'hawrah': 'Hooghly',
    'howrah': 'Hooghly',
    'hoorah': 'Hooghly',

    # West Bengal districts with alternate spellings
    'north 24 parganas': 'North 24 Parganas',
    'north twenty four parganas': 'North 24 Parganas',
    'south 24 parganas': 'South 24 Parganas',
    'south 24 pargana': 'South 24 Parganas',
    'south 24 parganas': 'South 24 Parganas',
    'paschim medinipur': 'Paschim Medinipur',
    'purba medinipur': 'Purba Medinipur',
    'west midnapore': 'Paschim Medinipur',
    'east midnapore': 'Purba Medinipur',
    'medinipur': 'Paschim Medinipur',
    'purba champaran': 'East Champaran',
    'pashchim champaran': 'West Champaran',

    # Bengaluru / Bangalore variants
    'bengaluru': 'Bengaluru',
    'bengaluru south': 'Bengaluru',
    'bengaluru rural': 'Bengaluru',
    'bangalore': 'Bengaluru',

    # Anantapur variants
    'anantapur': 'Ananthapuramu',
    'ananthapuramu': 'Ananthapuramu',

    # Medchal / Rangareddy variants
    'medchal-malkajgiri': 'Medchal-Malkajgiri',
    'medchal?malkajgiri': 'Medchal-Malkajgiri',
    'medchal−malkajgiri': 'Medchal-Malkajgiri',
    'rangareddy': 'Rangareddy',
    'k.v. rangareddy': 'Rangareddy',

    # Pondicherry
    'pondicherry': 'Puducherry',
    'puducherry': 'Puducherry',

    # Haveri / Harda
    'harda': 'Harda',
    'harda *': 'Harda',
    'haveri': 'Haveri',
    'haveri *': 'Haveri',

    # Malda / Maldah
    'malda': 'Malda',
    'maldah': 'Malda',

    # Nadia
    'nadia': 'Nadia',
    'nadia': 'Nadia',
    'NADIA': 'Nadia',

    # Jhajpur / Jajpur
    'jajpur': 'Jajpur',
    'jajpur': 'Jajpur',
    'JAJPUR': 'Jajpur',

    # Hooghly alternate spellings
    'hooghly': 'Hooghly',
    'hooghly': 'Hooghly',

    # Kanyakumari
    'kanyakumari': 'Kanniyakumari',
    'kanniyakumari': 'Kanniyakumari',

    # Other repeated or symbol-marked districts
    'buldhana': 'Buldana',
    'bulandshahar': 'Bulandshahr',
    'barddhaman': 'Bardhaman',
    'bardhaman': 'Bardhaman',
    'paschim bardhaman': 'Bardhaman',
    'purba bardhaman': 'Bardhaman',
    'bardez': 'North Goa',
    'raebareli': 'Rae Bareli',
    'raebareli': 'Rae Bareli',
    'raigarh(mh)': 'Raigarh',
    'shivpuri': 'Shivpuri',
    'karimnagar': 'Karimnagar',
    'karim nagar': 'Karimnagar',
    'karimganj': 'Karimganj',
    'chikmagalur': 'Chikkamagaluru',
    'chamarajanagar': 'Chamarajanagar',
    'chamarajanagar *': 'Chamarajanagar',
    'murshidabad': 'Murshidabad',
    'murshidabad': 'Murshidabad',

    # Misc common patterns / cleaning for asterisks / unicode spaces
    'harda  *': 'Harda',
    'anugul  *': 'Angul',
    'udupi *': 'Udupi',
    'gundiya *': 'Gondiya',
    'bagalkot *': 'Bagalkot',
    'nandurbar *': 'Nandurbar',
    'hingoli *': 'Hingoli',
    'gadag *': 'Gadag',

    # Unified formatting
    'mahendragarhchirmiribharatpur': 'Manendragarh–Chirmiri–Bharatpur',
    'manendragarh–chirmiri–bharatpur': 'Manendragarh–Chirmiri–Bharatpur',
    'janjgir champa': 'Janjgir-Champa',
    'janjgir-champa': 'Janjgir-Champa',
    'saraikela-kharsawan': 'Seraikela-Kharsawan',
    's.s.s. nagar (mohali)': 'SAS Nagar (Mohali)',
    'sas nagar (mohali)': 'SAS Nagar (Mohali)',

    # Multiple spellings / typos
    'yadgir': 'Yadgir',
    'yadadri.': 'Yadadri',
    'udhampur': 'Udhampur',
    'udhampur': 'Udhampur',
    'leh (ladakh)': 'Leh',
    'leparada': 'Nicobar',
    'nicobars': 'Nicobar',
    'hooghiy': 'Hooghly',
    'hooghly': 'Hooghly',
    'hooghly': 'Hooghly',
    'hooghly': 'Hooghly',
}

# Creating a list of all numerical columns to Group the Dataset by Districts and then by State

numerical_cols = ['bio_age_5_17', 'bio_age_17_']

census_2011 = pd.DataFrame({
    "state_2011": [
        "Andhra Pradesh","Arunanchal Pradesh","Assam","Bihar","Chhattisgarh",
        "Goa","Gujarat","Haryana","Himachal Pradesh","Jammu & Kashmir",
        "Jharkhand","Karnataka","Kerala","Madhya Pradesh","Maharashtra",
        "Manipur","Meghalaya","Mizoram","Nagaland","Odisha","Punjab",
        "Rajasthan","Sikkim","Tamil Nadu","Tripura","Uttar Pradesh",
        "Uttarakhand","West Bengal",
        "Andaman & Nicobar Island","Chandigarh",
        "Dadra & Nagar Havelli","Daman & Diu",
        "NCT of Delhi","Lakshadweep","Puducherry"
    ],

    "population_2011": [
        84665533,1382611,31169272,103804637,25540196,
        1457723,60383628,25353081,6856509,12548926,
        32966238,61130704,33387677,72597565,112372972,
        2721756,2964007,1091014,1980602,41947358,27704236,
        68621012,607688,72138958,3671032,199581477,
        25353235,91347736,
        379944,1054686,
        342853,159381,
        16753235,64429,1244464
    ]
})

"""## Important Functions"""

def clean_states(df):

  df['state'] = (
    df['state']
    .str.strip()                                            # Stripping spaces
    .str.lower()                                            # Making all the stripped strings to lowwer case
    .str.replace(r'\s+', ' ', regex=True)                   # Removing additional spaces in the middle of the stripped string
    .str.replace('&', 'and')                                # Replacing '&' --> 'and'
    )

  # Applying mapping
  df['state'] = df['state'].replace(state_mapping)

  # Formatting
  df['state'] = df['state'].str.title()

def map_state_to_2011(state):
    if state == "Telangana":
        return "Andhra Pradesh"
    elif state == "Dadra And Nagar Haveli And Daman And Diu":
        return "Dadra & Nagar Havelli"
    elif state in ["Jammu And Kashmir", "Ladakh"]:
        return "Jammu & Kashmir"
    elif state == "Delhi":
      return "NCT of Delhi"
    else:
        return state

def clean_districts(df):

  df['district'] = (
    df['district']
    .str.strip()                                      # Remove leading/trailing spaces
    .str.lower()                                      # Convert everything to lowercase
    .str.replace(r'\s+', ' ', regex=True)             # Remove extra spaces in the middle
    .str.replace(r'[\*\?\.\(\)]', '', regex=True)     # Remove special symbols (* ? . ())
    )

  # Applying mapping
  df['district'] = df['district'].replace(district_mapping)

  # Formatting nicely
  df['district'] = df['district'].str.title()

# seasons

def get_season(month):
    if month in [12, 1]:
        return "Winter"
    elif month in [2, 3]:
        return "Spring"
    elif month in [4, 5, 6]:
        return "Summer"
    elif month in [7, 8, 9]:
        return "Monsoon"
    else:
        return "Autumn"

# Getting Regions from States/UTs

def region(state):
  for region, states in regions.items():
    if state in states:
      return region

# Grouping by State and Date
def group_state(df):

  state_df = df.groupby(
    ['date', 'state'],
    as_index=False
    )[numerical_cols].sum()

  return state_df

# Grouping by District, State and Date
def group_district(df):

  dist_df = df.groupby(
    ['date', 'state', 'district'],
    as_index=False
    )[numerical_cols].sum()

  return dist_df

# Function to add features

def feature_creation(df):

  # --------------------------------------------------------------FROM NUMERICAL COLUMNS----------------------------------------------------------------------------------------

  # Creating a total biometric updates column
  df['bio_all'] = df['bio_age_17_'] + df['bio_age_5_17']

   # ------------------------------------------------------------------FROM STATE----------------------------------------------------------------------------------------

  df['state_ut'] = df['state'].apply(lambda x: 'UT' if x in UT else 'State')    # For Grouping States and UTs
  df['region'] = df['state'].apply(region)  # Getting Regions

   # --------------------------------------------------------------FROM DISTRICTS----------------------------------------------------------------------------------------
  if 'district' in df.columns:
    df['metro_city'] = df['district'].apply(lambda x: "is_metro" if x in metro_city else "is_not_metro")    # A binary mapping for Metro Cities


   # -------------------------------------------------------------------FROM DATE----------------------------------------------------------------------------------------

  df['month'] = df['date'].dt.month
  df['day'] = df['date'].dt.day
  df['weekday_numeric'] = df['date'].dt.weekday
  df['is_weekend'] = (df['date'].dt.weekday > 4).astype(int)
  df['weekday'] = df['date'].dt.day_name()
  df['quarter'] = df['date'].dt.quarter

  # Seasons
  df["season"] = df["month"].apply(get_season)

"""# Dataset"""

# Biometric Datasets

bio1 = pd.read_csv("/content/api_data_aadhar_biometric_0_500000.csv", parse_dates = ['date'], dayfirst = True)
bio2 = pd.read_csv("/content/api_data_aadhar_biometric_500000_1000000.csv", parse_dates = ['date'], dayfirst = True)
bio3 = pd.read_csv("/content/api_data_aadhar_biometric_1000000_1500000.csv", parse_dates = ['date'], dayfirst = True)
bio4 = pd.read_csv("/content/api_data_aadhar_biometric_1500000_1861108.csv", parse_dates = ['date'], dayfirst = True)

bio = pd.concat([bio1, bio2, bio3, bio4])

bio.head()

bio.info()

"""# Cleaning the Dataset

## State Column
"""

bio['state'].unique()

clean_states(bio)

len(set(bio['state']))

"""## District Column"""

bio['district'].nunique()

clean_districts(bio)

bio['district'].nunique()  # Since there are ~800 districts mapping each of them is not possible but here I saw a decrease from 974 to 917 unique districts.

"""> In the Data Cleaning Section, we have Cleaned the States and District Column

# Grouping
"""

bio_dist = group_district(bio)

bio_state = group_state(bio)

bio_state['state'].unique()

"""# Feature Creation"""

# Creating Features
feature_creation(bio_state)

feature_creation(bio_dist)

bio_state.sample(5)

bio_dist.sample(7)

"""## Creating bio_rate column

> Since we will use 2011 Census Data to calculate rate, first we have to Group the States as they were back in 2011
"""

bio_state["state_2011"] = bio_state["state"].apply(map_state_to_2011)

bio_state = bio_state.merge(
    census_2011,
    on="state_2011",
    how="left"
)

bio_state[bio_state["population_2011"].isna()]['state'].unique()

bio_state["bio_rate_per_100k"] = (
    bio_state["bio_all"] / bio_state["population_2011"]
) * 100000

bio_state["bio_rate_cat"] = pd.qcut(
    bio_state["bio_rate_per_100k"],
    q=5,
    labels=["Very Low", "Low", "Medium", "High", "Very High"]
)

bio_state['state_2011'].unique()

bio_state.sample(7)

"""# Exploratory Data Analysis"""

plt.figure(figsize=(8, 6))
sns.barplot(x = 'quarter', y = "bio_rate_per_100k", data = bio_state)
plt.title("Quarter-wise Average Update Rates (per 100k population)")
plt.show()

# Number of rows in each Dataset
bio_state.shape[0], bio_dist.shape[0]

"""> ### Descriptive Statistics"""

# For bio_states dataset
bio_state.describe()

# For bio_dist dataset
bio_dist.describe()

"""> ### Plots"""

sns.lineplot(x = "month", y = "bio_rate_per_100k", data = bio_state)
plt.show()

plt.figure(figsize=(8, 6))
sns.barplot(x = "region", y = "bio_rate_per_100k", data = bio_state)
plt.title("Regional Update Rates (normalized per 100k)")
plt.xticks(rotation = 90)
plt.show()

sns.boxenplot(x = 'is_weekend', y = "bio_rate_per_100k", data = bio_state)
plt.yscale('log')
plt.show()

sns.countplot(
    data=bio_state,
    x='bio_rate_cat',
    hue = 'is_weekend'
)

plt.show()

cat_heatmap = (
    bio_state
    .groupby(['region', 'bio_rate_cat'])
    .size()
    .reset_index(name='count')
)

cat_pivot = cat_heatmap.pivot(
    index='region',
    columns='bio_rate_cat',
    values='count'
).fillna(0)

plt.figure(figsize=(7,4))
sns.heatmap(
    cat_pivot,
    annot=True,
    fmt='g',
    cmap='YlGnBu'
)

plt.xlabel('bio_rate_cat Category')
plt.ylabel('Region')
plt.title('Distribution of bio_rate_cat Categories by Region')
plt.show()

"""# Choropleth Plot

## Dataset for Choropleth plot
"""

bio_choropleth = bio.groupby(
    ['state'],
    as_index = False,
)[numerical_cols].sum()

bio_choropleth['state'].unique()

bio_choropleth.head()

bio_choropleth['bio_all'] = bio_choropleth['bio_age_17_'] + bio_choropleth['bio_age_5_17']

bio_choropleth["state_2011"] = bio_choropleth["state"].apply(map_state_to_2011)

bio_choropleth = bio_choropleth.merge(
    census_2011,
    on="state_2011",
    how="left"
)

bio_choropleth["bio_rate_per_100k"] = (
    bio_choropleth["bio_all"] / bio_choropleth["population_2011"]
) * 100000

bio_choropleth["bio_rate_cat"] = pd.qcut(
    bio_choropleth["bio_rate_per_100k"],
    q=5,
    labels=["Very Low", "Low", "Medium", "High", "Very High"]
)

len(bio_choropleth['state_2011'].unique())

bio_choropleth[bio_choropleth['population_2011'].isna()]['state']

"""## Plot"""

import plotly.io as pio
pio.renderers.default = 'colab'

india_states = json.load(open("states_india.geojson", "r"))

state_id_map = {}
for feature in india_states["features"]:
    feature["id"] = feature["properties"]["state_code"]
    state_id_map[feature["properties"]["st_nm"]] = feature["id"]

state_id_map

missing_states = set(bio_choropleth["state_2011"]) - set(state_id_map.keys())
missing_states

# 1. Modify the GeoJSON properties to merge polygons into your new state name
for feature in india_states['features']:
    name = feature['properties']['st_nm']

    # If the map sees the old split names, tell it to look for your new merged name
    if name in ['Daman & Diu', 'Dadara & Nagar Havelli']:
        feature['properties']['st_nm'] = 'Dadra And Nagar Haveli And Daman And Diu'

    # Do the same for Telangana -> Andhra (for 2011 Census consistency)
    if name == 'Telangana':
        feature['properties']['st_nm'] = 'Andhra Pradesh'

bio_choropleth['id'] = bio_choropleth['state_2011'].apply(lambda x: state_id_map[x])

fig = px.choropleth(
    bio_choropleth, # Your aggregated dataframe
    geojson=india_states,
    locations="state",                # This matches your 'Dadra And...' object
    featureidkey="properties.st_nm",  # This matches the key we just edited
    color="bio_rate_per_100k",        # Or whatever your metric is
    hover_name="state",
    color_continuous_scale="YlGnBu"
)

fig.update_geos(fitbounds="locations", visible=False)
fig.show()

# 1. Modify the GeoJSON properties to merge polygons into your new state name
for feature in india_states['features']:
    name = feature['properties']['st_nm']

    # If the map sees the old split names, tell it to look for your new merged name
    if name in ['Daman & Diu', 'Dadara & Nagar Havelli']:
        feature['properties']['st_nm'] = 'Dadra And Nagar Haveli And Daman And Diu'

    # Do the same for Telangana -> Andhra (for 2011 Census consistency)
    if name == 'Telangana':
        feature['properties']['st_nm'] = 'Andhra Pradesh'

# 2. Plotting - Use 'state' as the location
fig = px.choropleth(
    bio_choropleth, # Your aggregated dataframe
    geojson=india_states,
    locations="state",                # This matches your 'Dadra And...' object
    featureidkey="properties.st_nm",  # This matches the key we just edited
    color="bio_rate_per_100k",        # Or whatever your metric is
    hover_name="state"
)

fig.update_geos(fitbounds="locations", visible=False)
fig.show()

with open("states_india.geojson") as f:
    india_states = json.load(f)

# Remove Telangana geometry to match Census 2011 boundaries
india_states["features"] = [
    feature for feature in india_states["features"]
    if feature["properties"]["st_nm"] != "Telangana"
]

[state["properties"]["st_nm"] for state in india_states["features"]]

bio_choropleth["state_2011"] = bio_choropleth["state"].replace({
    "Telangana": "Andhra Pradesh",
    "NCT of Delhi": "Delhi",
    "Dadara & Nagar Havelli And Daman And Diu": "Dadra & Nagar Haveli"
})

assert "Telangana" not in bio_choropleth["state_2011"].unique()

fig = px.choropleth(
    bio_choropleth, # Your aggregated dataframe
    geojson=india_states,
    locations="state",                # This matches your 'Dadra And...' object
    featureidkey="properties.st_nm",  # This matches the key we just edited
    color="bio_rate_per_100k",        # Or whatever your metric is
    hover_name="state"
)

fig.update_geos(fitbounds="locations", visible=False)
fig.show()

fig.update_geos(fitbounds="locations", visible=False)
fig.show()

# Create the ID map and modify the GeoJSON features simultaneously
state_id_map = {}
for feature in india_states["features"]:
    name = feature["properties"]["st_nm"]
    code = feature["properties"]["state_code"]

    # --- THE FIX ---
    # Force Telangana to use the Andhra Pradesh ID (28)
    if name == "Telangana":
        feature["id"] = 28
    # Force Daman & Diu to use the Dadara & Nagar Havelli ID (26)
    elif name == "Daman & Diu":
        feature["id"] = 26
    else:
        # Standard assignment for everyone else
        feature["id"] = code

    # Map the name to the ID we just assigned
    state_id_map[name] = feature["id"]

# Ensure "Andhra Pradesh" key exists even if it's the 2011 name
state_id_map["Andhra Pradesh"] = 28
state_id_map["Dadara & Nagar Havelli"] = 26

# Group by state_2011 to unify the counts
bio_map_df = bio_choropleth.groupby("state_2011", as_index=False).agg({
    "bio_all": "sum", # Sum up the updates
    "population_2011": "first" # Keep the population
})

# Recalculate the rate for the unified regions
bio_map_df["bio_rate_per_100k"] = (bio_map_df["bio_all"] / bio_map_df["population_2011"]) * 100000

# Assign the unified ID
bio_map_df['id'] = bio_map_df['state_2011'].map(state_id_map)

fig = px.choropleth(
    bio_map_df,
    locations="id",
    geojson=india_states,
    color="bio_rate_per_100k",
    hover_name="state_2011",
    color_continuous_scale="Viridis"
)
fig.update_geos(fitbounds="locations", visible=False)
fig.show()

"""# Saving the Datasets to use it in R for Further Analysis"""

# bio_dist.to_csv("bio_district.csv", index = False)

bio_state.to_csv("bio_state.csv", index = False)

bio_state.isna().sum()

